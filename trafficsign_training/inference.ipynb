{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load categories\n",
    "curr_dir = os.getcwd()\n",
    "# model = 'ssd_mobilenet'\n",
    "# model = 'ssd_inception'\n",
    "model = 'faster_rcnn'\n",
    "inference_results_dir = curr_dir + '/inference_results_'+ model\n",
    "try:\n",
    "    os.mkdir(inference_results_dir)\n",
    "except OSError:\n",
    "    pass\n",
    "frozen_graph_file = curr_dir + '/inference_graphs/'+model+'/frozen_inference_graph.pb'\n",
    "PATH_TO_LABELS = curr_dir + '/label_map.pbtxt'\n",
    "NUM_CLASSES =4\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "\n",
    "    with tf.gfile.GFile(frozen_graph_file, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "\n",
    "    sess = tf.Session(graph=detection_graph, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "num_detections = detection_graph.get_tensor_by_name('num_detections:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_classification(self, image):\n",
    "        \"\"\"Determines the color of the traffic light in the image\n",
    "\n",
    "        Args:\n",
    "            image (cv::Mat): image containing the traffic light\n",
    "\n",
    "        Returns:\n",
    "            int: ID of traffic light color (specified in styx_msgs/TrafficLight)\n",
    "\n",
    "        \"\"\"\n",
    "        traffic_light = TrafficLight.UNKNOWN\n",
    "\n",
    "        image_expanded = np.expand_dims(image, axis=0)\n",
    "        with self.detection_graph.as_default():\n",
    "            (boxes, scores, classes, num) = self.sess.run(\n",
    "                [self.detection_boxes, self.detection_scores,\n",
    "                 self.detection_classes, self.num_detections],\n",
    "                feed_dict={self.image_tensor: image_expanded})\n",
    "\n",
    "        boxes = np.squeeze(boxes)\n",
    "        scores = np.squeeze(scores)\n",
    "        classes = np.squeeze(classes).astype(np.int32)\n",
    "\n",
    "        min_score_threshold = .50\n",
    "        \n",
    "        class_name = None\n",
    "        for i in range(boxes.shape[0]):\n",
    "            if scores is None or scores[i] > min_score_threshold:\n",
    "\n",
    "                class_name = self.category_index[classes[i]]['name']\n",
    "\n",
    "                if class_name == 'Red':\n",
    "                    traffic_light = TrafficLight.RED\n",
    "                elif class_name == 'Green':\n",
    "                    traffic_light = TrafficLight.GREEN\n",
    "                elif class_name == 'Yellow':\n",
    "                    traffic_light = TrafficLight.YELLOW\n",
    "\n",
    "                self.image_np_deep = image\n",
    "\n",
    "        # rospy.loginfo('tl found: {}'.format(class_name))\n",
    "\n",
    "        return traffic_light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_images = []\n",
    "for dirname, dirnames, filenames in os.walk('inference_images'):\n",
    "    inference_images = filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (10, 6)\n",
    "durations =[]\n",
    "i=0\n",
    "with detection_graph.as_default():\n",
    "  with tf.Session(graph=detection_graph) as sess:\n",
    "    for filename in inference_images:\n",
    "        image_path = os.path.join('inference_images', filename)\n",
    "        image = Image.open(image_path)\n",
    "        # the array based representation of the image will be used later in order to prepare the\n",
    "        # result image with boxes and labels on it.\n",
    "        image_np = load_image_into_numpy_array(image)\n",
    "        # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "        image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "        # Actual detection.\n",
    "        a = datetime.datetime.now()\n",
    "        (boxes, scores, classes, num) = sess.run(\n",
    "          [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "          feed_dict={image_tensor: image_np_expanded})\n",
    "        b = datetime.datetime.now()\n",
    "        millis = (b - a).total_seconds() * 1000\n",
    "        i = i + 1\n",
    "        # ignore the first inference as it's usually an outlier(very slow)\n",
    "        if i > 1:\n",
    "            durations.append(millis)\n",
    "        print('Inference took: {}'.format(millis))\n",
    "        # Visualization of the results of a detection.\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np,\n",
    "            np.squeeze(boxes),\n",
    "            np.squeeze(classes).astype(np.int32),\n",
    "            np.squeeze(scores),\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            line_thickness=8)\n",
    "        fig = plt.figure(figsize=IMAGE_SIZE)\n",
    "        plt.imshow(image_np)\n",
    "        plt.savefig(inference_results_dir + '/'+ filename)\n",
    "#         plt.close()\n",
    "print('Average inference took: {}'.format(sum(durations)/len(durations)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
